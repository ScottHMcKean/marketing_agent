{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52e8c626-8524-4e20-b059-48da32162d05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-agents databricks-langchain langgraph==0.3.4 \n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f40dcadc-ccd9-44f9-a620-b02e1f3ca4f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.types.llm import ChatCompletionResponse, ChatCompletionRequest\n",
    "from mlflow.deployments import get_deploy_client\n",
    "import dataclasses\n",
    "\n",
    "eval_set = [\n",
    "  {\n",
    "    \"request\": \"What are the top 3 campaigns by opens?\",\n",
    "    \"expected_facts\": [\n",
    "      \"Warm Hearts, Warm Plates (campaign_id: 120) with 1,071 opens\",\n",
    "      \"Conquer the Kitchen (campaign_id: 149) with 997 opens\",\n",
    "      \"Dive into Wealth (campaign_id: 137) with 909 opens\"\n",
    "    ],\n",
    "    \"guidelines\": [\n",
    "      \"The response must be concise and include three campaigns\"\n",
    "    ]\n",
    "  }, {\n",
    "    \"request\": \"What is the cost of all the campaigns between January and February 2024?\",\n",
    "    \"expected_facts\": [\n",
    "      \"Based on the data provided, the total cost of all campaigns between January and February 2024 is $17,383.80.\"\n",
    "      ],\n",
    "    \"guidelines\": [\n",
    "      \"The response should say `based on the data provided`\"\n",
    "    ]\n",
    "  }]\n",
    "\n",
    "# Evaluate the agent with the evaluation set and log it to the MLFlow run \"system_prompt_v0\".\n",
    "with mlflow.start_run(run_name=\"agent_eval\") as run:\n",
    "  mlflow.evaluate(\n",
    "    data=eval_set,\n",
    "    model='models:/shm.marketing.genie_agent/2',\n",
    "    model_type=\"databricks-agent\"\n",
    "  )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "04_evaluation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
